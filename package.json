{
  "name": "chatgpt-openaiapi",
  "version": "1.0.7",
  "description": "ChatGPT with OpenAI API",
  "type": "commonjs",
  "main": "./src/main.js",
  "icon": "icon.png",
  "engines": {
    "node": ">= 18.12 <19",
    "hubai": ">= 0.1.0-alpha.13 || 1.x"
  },
  "scripts": {
    "start": "nodemon ./src/devServer.ts",
    "clean": "rimraf coverage build tmp",
    "prebuild": "npm run lint",
    "build": "tsc -p tsconfig.json",
    "build:watch": "tsc -w -p tsconfig.json",
    "package": "hubai brain package",
    "package:dev": "hubai brain package --selfHosted=http://127.0.0.1:1367",
    "lint": "eslint . --ext .ts --ext .mts",
    "test": "jest --coverage",
    "prettier": "prettier --config .prettierrc --write .",
    "test:watch": "jest --watch"
  },
  "brain": {
    "name": "ChatGPT",
    "displayName": "HubAI ChatGPT",
    "description": "HubAI brain that uses OpenAI API",
    "capabilities": [
      "conversation",
      "voice_transcription",
      "image_generation"
    ],
    "settingsMap": [
      {
        "displayName": "OpenAI API Key",
        "name": "apiKey",
        "type": "string",
        "required": true,
        "isSecret": true,
        "description": "Go to https://platform.openai.com/account/api-keys to get an API key and start using the OpenAI API"
      },
      {
        "displayName": "Text Model",
        "name": "textModel",
        "type": "string",
        "required": true,
        "defaultValue": "GPT 4o-mini",
        "enumValues": [
          "GPT 4o",
          "GPT 4o-mini"
        ],
        "scope": "chat_overridable",
        "capabilities": [
          "conversation"
        ]
      },
      {
        "displayName": "Max Characters History Size",
        "name": "maxCharactersHistorySize",
        "description": "The maximum number of characters to keep in the history of the conversation. The larger the number, the more context the AI will have about the conversation, but the slower the response time will be. A high number can increase the API bill.",
        "type": "integer",
        "required": false,
        "defaultValue": 3000,
        "scope": "chat_overridable",
        "capabilities": [
          "conversation"
        ]
      },
      {
        "displayName": "Audio Transcription Model",
        "name": "audioTranscriberModel",
        "type": "string",
        "required": true,
        "defaultValue": "whisper-1",
        "enumValues": [
          "whisper-1"
        ],
        "scope": "chat_overridable",
        "capabilities": [
          "voice_transcription"
        ]
      },
      {
        "displayName": "Audio Transcriber Language",
        "name": "audioTranscriberDefaultLanguage",
        "type": "string",
        "required": true,
        "defaultValue": "en",
        "enumValues": [
          "pt",
          "en",
          "es"
        ],
        "scope": "chat_overridable",
        "capabilities": [
          "voice_transcription"
        ]
      },
      {
        "displayName": "Image Generation Model",
        "description": "What model to use for generating an image. Dall-e 3 is the latest model released in Nov 2023. Dall-e 2 is the previous model released in Nov 2022. Dall-e 3 is slower, but generates better images.",
        "name": "imageGenerationModel",
        "type": "string",
        "required": true,
        "defaultValue": "Dall-E 2",
        "enumValues": [
          "Dall-E 2",
          "Dall-E 3"
        ],
        "scope": "chat_overridable",
        "capabilities": [
          "image_generation"
        ]
      },
      {
        "displayName": "Image Generation Size (Pixels)",
        "description": "The resolution of the images generated by the model. Smaller sizes are faster to generate",
        "name": "imageGenerationSize",
        "type": "string",
        "required": true,
        "defaultValue": "256x256",
        "enumValues": [
          "256x256",
          "512x512",
          "1024x1024"
        ],
        "scope": "chat_overridable",
        "capabilities": [
          "image_generation"
        ]
      },
      {
        "displayName": "Image Generation Count",
        "description": "Number of images to generate",
        "name": "imageGenerationCount",
        "type": "string",
        "required": true,
        "defaultValue": "1",
        "enumValues": [
          "1",
          "2",
          "3",
          "4",
          "5",
          "6",
          "7",
          "8",
          "9",
          "10"
        ],
        "scope": "chat_overridable",
        "capabilities": [
          "image_generation"
        ]
      },
      {
        "displayName": "Image Vision Details",
        "description": "How much detail we should read from the image. Low will generate faster response times, but will not be able to recognize small details. High will generate slower response times, but will be able to recognize small details.",
        "name": "imageDetail",
        "type": "string",
        "required": true,
        "defaultValue": "low",
        "enumValues": [
          "low",
          "high"
        ],
        "scope": "chat_overridable",
        "capabilities": [
          "conversation"
        ]
      }
    ]
  },
  "publisher": "hubai",
  "devDependencies": {
    "@types/jest": "~29.5",
    "@types/node": "~18",
    "@typescript-eslint/eslint-plugin": "~5.59",
    "@typescript-eslint/parser": "~5.59",
    "body-parser": "^1.20.2",
    "eslint": "~8.38",
    "eslint-config-prettier": "~8.8",
    "eslint-plugin-jest": "~27.2",
    "express": "^4.18.2",
    "jest": "~29.5",
    "nodemon": "^3.0.1",
    "prettier": "~2.8",
    "rimraf": "~5.0",
    "ts-api-utils": "~0.0.44",
    "ts-jest": "~29.1",
    "ts-node": "^10.9.1",
    "typescript": "~5.0"
  },
  "author": "hubai",
  "keywords": [
    "ChatGPT",
    "OpenAI",
    "gpt",
    "chat",
    "open"
  ],
  "categories": [
    "brain"
  ],
  "license": "Apache-2.0",
  "dependencies": {
    "@hubai/brain-sdk": "^1.0.8",
    "openai": "^4.16.1",
    "tslib": "~2.5"
  },
  "volta": {
    "node": "18.12.1"
  }
}
